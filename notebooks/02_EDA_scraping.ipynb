{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9671d3f2",
   "metadata": {},
   "source": [
    "# Comment analysis\n",
    "- Some search doesn't match properly: Praça Bartolomeu de Gusmão\n",
    "\n",
    "# Objectives\n",
    "1. Explore downloaded data\n",
    "2. Data cleaning\n",
    "3. Analysis of score of every place\n",
    "4. Words analysis\n",
    "5. Spatial distribution of scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import sqlite3\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import folium\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import fcluster \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329131a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd(), os.listdir('./'))\n",
    "os.chdir('./../')\n",
    "print(os.getcwd(), os.listdir('./'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOME_DB = \"data/raw/scrapcomments.db\"\n",
    "with sqlite3.connect(NOME_DB) as connection:\n",
    "    df = pd.read_sql('SELECT * FROM googleplaces', connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1798bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e59772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f0ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1598 - 801 = 797 Duplicates\n",
    "df = df.drop_duplicates(subset=['url', 'Comentario'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d628e",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Estrellas'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54063ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095a2d1",
   "metadata": {},
   "source": [
    "# Time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff7e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fecha'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ade0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping words\n",
    "MAPA_TIEMPO = {\n",
    "    'years': ['ano', 'anos', 'año', 'años'],\n",
    "    'months': ['mês', 'meses', 'mes'],\n",
    "    'weeks': ['semana', 'semanas'],\n",
    "    'days':   ['dia', 'dias', 'día', 'días'],\n",
    "    'hours':  ['hora', 'horas'],  # Extra: por si aparecen horas\n",
    "}\n",
    "\n",
    "def convertir_fecha_dinamica(texto):\n",
    "    \"\"\"\n",
    "    Convierte texto como 'há 6 anos' en un objeto datetime real\n",
    "    usando extracción dinámica de números y unidades.\n",
    "    \"\"\"\n",
    "    # 1. Normalización básica\n",
    "    if pd.isna(texto): return pd.NaT\n",
    "    # Pasamos a minúsculas y limpiamos espacios\n",
    "    t = str(texto).lower().strip()\n",
    "    \n",
    "    # Fecha base (Hoy) normalizada a las 00:00:00\n",
    "    hoy = pd.Timestamp.now().normalize()\n",
    "\n",
    "    # 2. Extracción del VALOR (Entero)\n",
    "    cantidad = 0\n",
    "    \n",
    "    # Caso especial: palabras textuales como \"um\" o \"uma\"\n",
    "    if 'um ' in t or 'uma ' in t: # Espacio para no confundir con 'algUMa'\n",
    "        cantidad = 1\n",
    "    else:\n",
    "        # Regex: Busca cualquier secuencia de dígitos (\\d+)\n",
    "        coincidencia = re.search(r'(\\d+)', t)\n",
    "        if coincidencia:\n",
    "            cantidad = int(coincidencia.group(1))\n",
    "        else:\n",
    "            return pd.NaT # Si no hay número ni 'um', no podemos calcular\n",
    "\n",
    "    # 3. Detección de la UNIDAD (Dinámica)\n",
    "    # Recorremos nuestro diccionario de configuración\n",
    "    for unidad_pandas, palabras_clave in MAPA_TIEMPO.items():\n",
    "        # Verificamos si alguna palabra clave está en el texto\n",
    "        if any(palabra in t for palabra in palabras_clave):\n",
    "            \n",
    "            # 4. Cálculo Matemático (Magia de Pandas)\n",
    "            # Creamos un diccionario dinámico con el parámetro correcto\n",
    "            # Equivale a decir: DateOffset(years=6) o DateOffset(months=3)\n",
    "            kwargs = {unidad_pandas: cantidad}\n",
    "            return hoy - pd.DateOffset(**kwargs)\n",
    "\n",
    "    # Si llegamos aquí, detectamos número pero no la unidad (ej: \"há 6 ???\")\n",
    "    return pd.NaT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02045c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply custom function to extract time data\n",
    "print(\"Calculando fechas...\")\n",
    "df['Fecha_Calculada'] = df['Fecha'].apply(convertir_fecha_dinamica)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67009dc7",
   "metadata": {},
   "source": [
    "# Simple exploratory comments\n",
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargamos las palabras vacías (solo la primera vez)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Convertimos a string por si hay algún dato numérico suelto y eliminamos vacíos\n",
    "df['Comentario'] = df['Comentario'].astype(str).fillna('')\n",
    "\n",
    "# 2. DEFINIR STOPWORDS (Palabras a ignorar)\n",
    "# Usamos la lista de español de NLTK y añadimos algunas propias que no aportan valor\n",
    "stop_words_es = stopwords.words('portuguese')\n",
    "# Añadimos palabras \"basura\" típicas de reviews que ensucian el gráfico\n",
    "nuevas_stopwords = ['lar', 'sitio', 'ir', 'ver', 'mas', 'si', 'tan', 'parco', 'verde'] \n",
    "stop_words_es.extend(nuevas_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc179f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_nube(texto_completo, titulo):\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, \n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        stopwords=stop_words_es,\n",
    "        min_font_size=10\n",
    "    ).generate(texto_completo)\n",
    "\n",
    "    plt.figure(figsize=(10, 5), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(titulo, fontsize=20)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307bb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generando Nube de Palabras General...\")\n",
    "texto_general = \" \".join(review for review in df.Comentario)\n",
    "generar_nube(texto_general, \"Palabras más usadas en Parco Verde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963412c",
   "metadata": {},
   "source": [
    "## B-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc5c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_bigramas(corpus, n=10):\n",
    "    # CountVectorizer counting pairs of words (ngram_range=(2,2))\n",
    "    vec = CountVectorizer(ngram_range=(2, 2), stop_words=stop_words_es).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    \n",
    "    # Sum of the word frequencies \n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    \n",
    "    # Order frequency\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get first n pair\n",
    "    top_words = words_freq[:n]\n",
    "    \n",
    "    # Separamos para graficar\n",
    "    x, y = zip(*top_words) # x=words, y=frequency\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(x, y, color='skyblue')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title('Top 10 Pares de Palabras (Bigramas) más comunes')\n",
    "    plt.xlabel('Frecuencia')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9633bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generando Bigramas...\")\n",
    "grafico_bigramas(df['Comentario'], n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a27412",
   "metadata": {},
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cfbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Estrellas'] = df['Estrellas'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2448bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "analisis_temporal = df.groupby(pd.Grouper(key='Fecha_Calculada', freq='M')).agg({'Estrellas': 'mean'})\n",
    "print(analisis_temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of stars over the time column\n",
    "analisis_temporal['Estrellas'].plot(kind='line', marker='o', color='orange', figsize=(10,5))\n",
    "\n",
    "plt.title(\"Evolución de la Calidad (Estrellas) por Mes\")\n",
    "plt.ylabel(\"Estrellas (1-5)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49eb177",
   "metadata": {},
   "source": [
    "# Spatial comments analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates\n",
    "# (?P<Latitud>...) assign a new column\n",
    "patron = r'@(?P<Latitud>-?\\d+\\.\\d+),(?P<Longitud>-?\\d+\\.\\d+)'\n",
    "\n",
    "# 3. Aplicamos la extracción mágica\n",
    "# Esto busca el patrón en cada fila y separa los grupos en nuevas columnas\n",
    "coordenadas = df['url'].str.extract(patron)\n",
    "\n",
    "# 4. Convertimos a números (porque se extraen como texto)\n",
    "coordenadas = coordenadas.astype(float)\n",
    "\n",
    "# 5. Unimos las nuevas columnas a tu DataFrame original\n",
    "df_final = pd.concat([df, coordenadas], axis=1)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "analisis_temporal = df_final.groupby(by='url').agg({'Estrellas': 'mean',\n",
    "                                              'Latitud': 'max',\n",
    "                                              'Longitud': 'max',\n",
    "                                              'search_word': 'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af87b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "analisis_temporal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feat, y_feat = 'Longitud', 'Latitud'\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "ax.scatter(analisis_temporal[x_feat], analisis_temporal[y_feat], s=2)\n",
    "plt.ylabel(y_feat)\n",
    "plt.xlabel(x_feat)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/raw/espacios_verdes_coimbra.geojson\"\n",
    "gdf_parques = gpd.read_file(file_name)\n",
    "gdf = gdf_parques.loc[gdf_parques['name'].notna(), :].copy()\n",
    "gdf['name'].str.lower().to_list()\n",
    "lon, lat = np.mean(gdf_parques[\"geometry\"].centroid.x), np.mean(gdf_parques[\"geometry\"].centroid.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tag:workspaceTrust\n",
    "m = folium.Map(location=[lat, lon], zoom_start=10, tiles='OpenStreetMap')\n",
    "\n",
    "# --- PARTE A: TU CÓDIGO (POLÍGONOS / BARRIOS) ---\n",
    "# Iteramos sobre el GeoDataFrame (gdf)\n",
    "for _, r in gdf.iterrows():\n",
    "    # Simplificamos la geometría para que el mapa cargue rápido\n",
    "    sim_geo = gpd.GeoSeries(r[\"geometry\"]).simplify(tolerance=0.001)\n",
    "    geo_j = sim_geo.to_json()\n",
    "    \n",
    "    # Creamos la capa GeoJson\n",
    "    geo_j_layer = folium.GeoJson(\n",
    "        data=geo_j, \n",
    "        style_function=lambda x: {\"fillColor\": \"orange\", \"color\": \"orange\", \"weight\": 1, \"fillOpacity\": 0.3}\n",
    "    )\n",
    "    \n",
    "    # Añadimos popup con el nombre de la zona\n",
    "    folium.Popup(r[\"name\"]).add_to(geo_j_layer)\n",
    "    geo_j_layer.add_to(m)\n",
    "\n",
    "# --- PARTE B: NUEVO CÓDIGO (PUNTOS DE COORDENADAS) ---\n",
    "# Iteramos sobre el DataFrame de coordenadas (df)\n",
    "for index, row in analisis_temporal.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['Latitud'], row['Longitud']],\n",
    "        tooltip=row['search_word'], # Aparece al pasar el ratón (hover)\n",
    "        popup=folium.Popup(f\"<b>{row['search_word']} ,  {row['Estrellas']}</b>\", max_width=300), # Aparece al hacer clic\n",
    "        icon=folium.Icon(color=\"blue\", icon=\"info-sign\") # Icono azul\n",
    "    ).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517009fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer polygon\n",
    "gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff3c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot park polygons and locations with gradient rampmap color\n",
    "x_feat, y_feat, size = 'Longitud', 'Latitud', 'Estrellas'\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "ax = gdf.plot(facecolor=\"#B01F1F\", alpha=0.5, linewidth=0.01, hatch=\"//\", ax=ax)\n",
    "ax = ax.scatter(analisis_temporal[x_feat], analisis_temporal[y_feat], s=(analisis_temporal[size]+30), c=analisis_temporal[size])\n",
    "plt.ylabel(y_feat)\n",
    "plt.xlabel(x_feat)\n",
    "cbar = plt.colorbar(ax)\n",
    "cbar.set_label(size)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f42f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data in processed folder\n",
    "analisis_temporal.loc[:, ['search_word', 'Estrellas', 'Longitud', 'Latitud']].to_csv('data/processed/parcoverde.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500775bc",
   "metadata": {},
   "source": [
    "# Unsupervised learning\n",
    "Hierarchical Clustering\n",
    "https://dashee87.github.io/data%20science/general/Clustering-with-Scikit-with-GIFs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ac68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupacion_jerarquica(df, ls_cols, nombre_barrio, dist=3, method='ward',\n",
    "                          metric='euclidean', optimal_ordering=False):\n",
    "    mosaicstr=\"\"\"\n",
    "    ab\n",
    "    ab\n",
    "    cb\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplot_mosaic(mosaic=mosaicstr, figsize=(10, 6))\n",
    "    # relacion entre pares de instancias, distancia y acumulado\n",
    "    # Metodo aglomerativo, no divisivo\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html\n",
    "    Z = linkage(df.loc[:, ls_cols].values, method, \n",
    "                metric, optimal_ordering=optimal_ordering)\n",
    "    kden = dendrogram(Z, ax=ax['a'], color_threshold=dist)\n",
    "    ax['a'].axhline(y=dist, color='r', linestyle='--')\n",
    "    ax['a'].set_title(f\"Dendograma - método {method}\")\n",
    "    ax['a'].set(xlabel='Parco', ylabel='Distancia')\n",
    "    agglo_clusters = fcluster(Z, t=dist,criterion='distance')\n",
    "    print(\"Nº Clusters: \", np.unique(agglo_clusters).shape[0])\n",
    "    ax['b'].set_title(f\"Clustering distribution k={np.unique(agglo_clusters).shape[0]}\")\n",
    "    ax['b'].set(xlabel=ls_cols[0], ylabel=ls_cols[1])\n",
    "    axb = ax['b'].scatter(df[ls_cols[0]], df[ls_cols[1]], \n",
    "                          c=agglo_clusters, cmap='Dark2', s=20)\n",
    "\n",
    "    ax['b'].legend()\n",
    "    cbar = plt.colorbar(axb)\n",
    "    cbar.set_label('k-clusters')\n",
    "    ax['c'].plot(Z[:, 2])\n",
    "    ax['c'].axhline(y=dist, color='r', linestyle='--')\n",
    "    # ax['c'].set_title(f\"Distancia en la aglomeración\")\n",
    "    ax['c'].set(xlabel='Nº parcos acumulados', ylabel='Distancia')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return kden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29191087",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = agrupacion_jerarquica(df=analisis_temporal, nombre_barrio='search_word', \n",
    "                           dist=0.01, ls_cols=['Longitud', 'Latitud'], \n",
    "                           method='ward', metric='euclidean', \n",
    "                           optimal_ordering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1932a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "lscol = ['Longitud', 'Latitud', 'Estrellas']\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "minmx = min_max_scaler.fit(analisis_temporal.loc[:, lscol])\n",
    "df2cluster = pd.DataFrame(minmx.transform(analisis_temporal.loc[:, lscol]), columns=lscol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = agrupacion_jerarquica(df=df2cluster, nombre_barrio='search_word', \n",
    "                           dist=1.2, ls_cols=['Longitud', 'Latitud', 'Estrellas'], \n",
    "                           method='ward', metric='euclidean', \n",
    "                           optimal_ordering=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60313cb",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
