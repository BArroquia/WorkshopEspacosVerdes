{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hola colegas!\n",
    "## Tudo bem?\n",
    "### Todo bien\n",
    "\n",
    "Vamos a hacer un proyecto sobre espacios verdes\n",
    "\n",
    "> Estamos en Jupyter y esto es Markdown\n",
    "\n",
    "# Jupyter notebook\n",
    "\n",
    "## Markdown\n",
    "\n",
    "Fichero de texto con extensión .md en la que se recoje documentación de forma estructurada: [Markdown](https://www.markdownguide.org/)\n",
    "\n",
    "> **Tip**\n",
    ">\n",
    "> En programación y en proyectos de Ciencia de Datos es de uso muy extendido. \n",
    "\n",
    "## Jupyter notebook en Ciencia de Datos\n",
    "\n",
    "- Presentaciones, ejercicios, actividades... __todo__ notebooks\n",
    "- Markdown/HTML + codigo en vivo\n",
    "- Facilita la colaboración y la presentación interactiva de código\n",
    "- En la terminal: __jupyter notebook__\n",
    "- Archivos _.ipynb_\n",
    "- Documentación https://jupyter.readthedocs.io/en/latest/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O problema\n",
    "\n",
    "Sabemos que os espaços verdes urbanos têm efeitos positivos na saúde e na dinâmica das cidades.\n",
    "\n",
    "Queremos melhorar esses espaços e contribuir para a melhoria da qualidade de vida nas cidades.\n",
    "\n",
    "Como podemos estudar o estado atual dos espaços verdes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de ciência de dados\n",
    "\n",
    "The KDD Process for Extracting Useful Knowledge from Volumes of Data\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/240455.240464\n",
    "\n",
    "> \"The nontrivial process of identifying valid, novel, potentially useful, and ultimately understandable patterns in data.\"\n",
    "\n",
    "Aqui está uma proposta estruturada para o seu *workshop*, desenhada especificamente para o contexto de Portugal (utilizando o português europeu e referências locais), seguindo o fluxo de trabalho que definiu: Aquisição (OSM) -> Extração (Scraping) -> Visualização -> Análise.\n",
    "\n",
    "### Esquema do Workshop (Estrutura Programática)\n",
    "\n",
    "1.  **Módulo 1: Cartografia Digital e Aquisição de Dados**\n",
    "    *   Introdução ao OpenStreetMap (OSM) como fonte de dados abertos.\n",
    "    *   Utilização da biblioteca `OSMnx` em Python.\n",
    "    *   Extração de geometrias (polígonos) de espaços verdes.\n",
    "    *   Projeção de coordenadas.\n",
    "\n",
    "2.  **Módulo 2: Mineração de Opinião Pública - Web Scraping**\n",
    "    *   Identificação dos Pontos de Interesse no Google Maps.\n",
    "    *   Configuração do ambiente de *scraping* (Playwright).\n",
    "    *   Automação da navegação e extração de comentários e classificações (estrelas).\n",
    "    *   Ética na extração de dados e anonimização.\n",
    "\n",
    "3.  **Módulo 3: Visualização de Dados Geoespaciais**\n",
    "    *   Limpeza e estruturação dos dados (Pandas/GeoPandas).\n",
    "    *   Criação de mapas interativos com `Folium`.\n",
    "\n",
    "4.  **Módulo 4: Análise de Sentimento e NLP**\n",
    "    *   Processamento de Linguagem Natural (NLP) para português.\n",
    "    *   Análise de sentimentos (Positivo/Negativo/Neutro) nos comentários extraídos.\n",
    "    *   Extração de palavras-chave (ex: \"limpeza\", \"segurança\", \"ruído\").\n",
    "    *   Conclusões e *insights* para o planeamento urbano.\n",
    "\n",
    "## Perguntas no final do projeto\n",
    "quoted from Fayyad:\n",
    "1. The discovered patterns should be valid for new data with some degree of certainty\n",
    "2. We also want patterns to be novel \n",
    "3. Potentially useful for the user or task\n",
    "4. The patterns should be understandable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Estuctura de cartpetas\n",
    "\n",
    "```\n",
    "EspaciosVerdes/\n",
    "├── data/\n",
    "│    ├── raw/\n",
    "│    └── processed/\n",
    "│        ├── espacosverdes.csv\n",
    "│        └── ...\n",
    "├── documents/\n",
    "│   ├── 1_configuracion_ds.md\n",
    "│   └── ...\n",
    "├── notebooks/\n",
    "│   ├── EDA.ipynb\n",
    "│   └── ...\n",
    "├── scripts/\n",
    "│   ├── dbconnect.py\n",
    "│   └── ...\n",
    "├── README.md\n",
    "├── .gitignore\n",
    "└── venv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets have some code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor 503124019814 para la variable\n"
     ]
    }
   ],
   "source": [
    "# Hello world!!\n",
    "a = 503124019814\n",
    "\n",
    "print(f\"el valor {a} para la variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tengo otra celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n",
      "9\n",
      "holaholahola\n"
     ]
    }
   ],
   "source": [
    "# funcion para sumar dos elementos\n",
    "def suma(a, b):\n",
    "    return a+b\n",
    "\n",
    "lista = [1,2,3]\n",
    "lista = [1,2,3, 'hola']\n",
    "lista\n",
    "\n",
    "for i in lista:\n",
    "    # print(i+i)\n",
    "    print(suma(i, i+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sesion:\n",
    "    def __init__(self, titulo, fecha, profesor):\n",
    "        self.titulo = titulo\n",
    "        self.fecha = fecha\n",
    "        self.profesor = profesor\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Sesión: {self.titulo}, Fecha: {self.fecha}, Duración: {self.profesor}\"\n",
    "\n",
    "class SesionTeorica(Sesion):\n",
    "    def __init__(self, titulo, fecha, profesor, tema):\n",
    "        super().__init__(titulo, fecha, profesor)\n",
    "        self.tema = tema\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Sesión Teórica: {self.titulo}, Tema: {self.tema}, Fecha: {self.fecha}, Profesor: {self.profesor}\"\n",
    "\n",
    "class SesionPractica(Sesion):\n",
    "    def __init__(self, titulo, fecha, profesor, actividad):\n",
    "        super().__init__(titulo, fecha, profesor)\n",
    "        self.actividad = actividad\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Sesión Práctica: {self.titulo}, Actividad: {self.actividad}, Fecha: {self.fecha}, Profesor: {self.profesor}\"\n",
    "\n",
    "class Asignatura:\n",
    "    def __init__(self, nombre):\n",
    "        self.nombre = nombre\n",
    "        self.sesiones = []\n",
    "\n",
    "    def agregar_sesion(self, sesion):\n",
    "        self.sesiones.append(sesion)\n",
    "\n",
    "    def __str__(self):\n",
    "        sesiones_str = \"\\n\".join(str(sesion) for sesion in self.sesiones)\n",
    "        return f\"Asignatura: {self.nombre}\\nSesiones:\\n{sesiones_str}\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "asignatura = Asignatura(\"Introducción a la Ciencia de Datos\")\n",
    "sesion1 = SesionTeorica(\"KDD y CRIPS-DM\", \"2025-02-13\", \"Horacio Kuna\", \"Tema 2\")\n",
    "sesion2 = SesionPractica(\"Foro y configuración\", \"2025-02-18\", \"Benjamin Arroquia Cuadros\", \"Práctica 1\")\n",
    "\n",
    "asignatura.agregar_sesion(sesion1)\n",
    "asignatura.agregar_sesion(sesion2)\n",
    "\n",
    "print(asignatura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use libraries\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = [4, 6, 7, 5, 6]\n",
    "random.choice(list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_data = []\n",
    "ls_range = list(range(1000))\n",
    "for i in ls_range:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_list = np.random.randint(200,size=(3, 3))\n",
    "print(random_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(3,3)\n",
    "B = np.random.rand(3,1)\n",
    "print(A)\n",
    "# print(A @ B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(100,size=(4,2))\n",
    "display(data)\n",
    "print(data[0, :], data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0, 20, 1000)\n",
    "y = np.sin(X) + 0.2 * X\n",
    "display(y)\n",
    "display(data)\n",
    "X = np.random.randn(100, 2)\n",
    "X[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datos de ejemplo\n",
    "x = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "y = np.array([2, 3, 5, 7, 11])\n",
    "\n",
    "X = np.hstack([x, np.ones((x.shape[0], 1))])\n",
    "coeficientes = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "pendiente1, pendiente2, intersección = coeficientes\n",
    "\n",
    "print(f\"Pendiente 1: {pendiente1}\")\n",
    "print(f\"Pendiente 2: {pendiente2}\")\n",
    "print(f\"Intersección: {intersección}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X = np.random.randn(200, 2)\n",
    "X[:50] += 4\n",
    "Y = np.zeros(200)\n",
    "Y[:50] = 1\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "frame = pd.DataFrame(random_list)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1 = pd.Series(['Spain','Andorra',\n",
    "           'Gibraltar','Portugal','France'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sr1)\n",
    "# ls1 = [1, 3, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario = { \"Nombre\" : [\"Marisa\",\"Laura\",\"Manuel\"], \n",
    "                \"Edad\" : [34,29,12] }\n",
    "\n",
    "# las claves identifican columnas\n",
    "frame = pd.DataFrame(diccionario, index=['a', 'b', 'c'])\n",
    "display(frame)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
